# ML
## Coursera - Hyperparameter Tuning
이제까지 신경망을 학습시킬 때 사용하는 여러 하이퍼파라미터들(레이어, 히든유닛, 학습률 알파, 베타, 미니배치사이즈, 모멘텀파라미터 등등)을 알아보았다. <br>
그럼 이 **많은 하이퍼파라미터들 중에 좋은 하이퍼파라미터를 어떻게 찾을 수 있을까?**
체계적으로 하이퍼 파라미터를 튜닝할 수 있는 법을 알아보자.


### 대충 앤드류 응이 생각하는 하이퍼 파라미터 중요도 순위
- 1. α (학습률)
- 2. 모멘텀 β (0.9)
- 2. 미니배치 사이즈
- 3. 히든유닛
- 3. 레이어
- 3. 학습률 감쇠

### 머신러닝에서 하이퍼파라미터들을 정하는 법들.
수많은 하이퍼파라미터중에 어떤 하이퍼파라미터가 문제해결에 더 중요한지를 모르기 때문에 **무작위로 정해야한다.** 은닉유닛수를 정한다고 치면 50부터 100까지의 값들을 수직선상에 세워두고 무작위하게 값을 고를 수 있을 것이다. 그런데 모든 파라미터가 이렇게 적용되지는 않는다. 그래서 **적절한 척도를 두고 무작위로 골라야한다.**

#### 로그척도사용하기
- e.g) 학습률 α를 정한다고 치자.
    - 범위를 0.0001부터 1까지 생각할 것이다.
    - 만약, 균일하게 정한다면 0.0001에서 1까지의 값들 중에서 하나를 고를 것이다.
    - 하지만 이럴 경우 자원이 낭비된다.
        - 0.0001과 0.1 사이의 값을 탐색해서 골랐다치면 나머지 0.1과 1사이를 탐색하는 것에 90%의 자원이 쓰이고 단 10%의 자원만이 0.0001과 0.1 사이의 값을 탐색하는 것에 쓰인 것이다. 비효율적이다.
    - 그래서 선형으로 숫자를 쭉 나열해서 고르지 않고 **로그 척도를 사용한다.**
        - 로그척도를 사용하게되면 0.0001, 0.001, 0.01, 0.1로 나뉜 로그 척도 위에서 탐색하기 때문에 앞에서와 같이 0.1과 1 사이에서 90%의 자원을 때려박지 않게되고, 한정된 곳에 더 많은 자원을 사용할 수 있게 된다.

```python
# -4에서 0사이의 무작위 값을 골라보자
r = -4*np.random.rand()
a = 10^r
```

     - -4 에서 0까지의 숫자를 무작위로 고르고 10의 지수로 씌워주면 예를 들었던 로그척도 완성!

- 지수가중평균을 계산할 때 사용되는 하이퍼파라미터 β 도 이런 식으로 정해진다.


#### 두번째 방법 정밀화 접근
성능이 좋은 하이퍼파라미터들을 찾아서 그 안에서 더 조밀하게 하이퍼파라미터들을 조정할 수 있다.


### 하이퍼파라미터는 어떻게 탐색할 수 있을까?
여러 분야에 적용되고 있는 딥러닝은 한 분야에서 잘 먹혔던 하이퍼파라미터가 다른 분야에서는 안 먹힐 수가 있다. <br>
그리고 하이퍼파라미터들은 만족할만한 결과를 낼 때까지 계속해서 평가되고 수정된다. 이 과정을 어떤 방식으로 할까? 컴퓨터 자원에 따라 다음의 두 가지의 방식을 쓴다.

#### `Babysitting one model (모델 돌보기)`
데이터는 방대하지만 CPU/GPU 같은 컴퓨터 성능이 좋지않아서 적은 숫자의 모델을 한번에 학습시킬 때 사용한다.
학습 과정에서 모델을 돌보는 다음과 같은 과정을 거친다.
- 0일차에 무작위하게 하이퍼파라미터들을 설정하고 학습을 시작
- 학습곡선에서 비용함수나 valid세트의 오차가 줄어들 것이다.
- 1일차에 학습이 잘 됐는지 확인한다.
- 학습속도를 조금씩 올려서 더 나아지는지 본다.
- 2일차에도 학습이 잘 됐는지 확인한다.
- 모멘텀을 약간 올리거나 학습 속도를 약간 낮춰본다.

이런식으로 몇주, 몇달 동안 모델을 돌보면서 학습을 시키는 것이다. 여러모델을 동시에 학습시킬 자원이 충분하지 않을 때 사용한다. <br>
앤드류 응은 한 마리의 새끼를 엄청나게 돌보는 판다에 이를 비유했다. 커뮤니티를보면 온라인광고, 컴퓨터비전과같이 큰 모델들은 이 방식을 사용한다고하더라.

#### `Training many models in parallel (여러 모델을 함께 학습시키기)` 
- 동시에 각각의 모델에 다른 하이퍼파라미터를 적용하여 학습시킨다.
- 각각의 모델의 결과를 본다.
- 최고의 성능을 내는 하이퍼파라미터를 적용한다.
앤드류 응은 한 철에 1억개의 알을 낳는 캐비어에 비유했다.


<br><br><br>

## Coursera - Batch Normailization
하이퍼파라미터들을 살펴보며 최적화를 어떻게 시킬 수 있는지를 확인했다. 하이퍼파라미터를 잘 선택할 수 있는 또 다른 테크닉인 Batch Normailization 을 살펴보자. 모든 신경망에 적용되진 않지만 적용이 가능하다면 하이퍼파라미터 탐색이 훨씬 쉽고 빨라진다. <br>

### `Batch Normailization`
하이퍼파라미터 탐색을 쉽게 만들어줄 뿐만아니라 신경망과 하이퍼파라미터의 상관관계를 줄여주어 더 많은 하이퍼파라미터가 잘 작동하게 만들어준다. 또한 아주 깊은 심층 신경망이라도 아주 쉽게 학습하 수 있도록 해준다. 와오... 그래서 ML 에서 아주 중요한가보다.

#### 어떻게 작용할까
로지스틱 회귀에서는 인풋값 x를 normalization 하여 w,b에 영향을 주었다. 그럼 심층신경망에서 은닉유닉 a^[n]을 normailzation 하면 w^[n+1], b^[n+1] 에 영향을 줄까? 이것이 `Batch Normailization` 가 하는 일을 나타내는 것이다.(실제로는 a^[n]이 아니라 활성화 함수를 적용하기 전인 z^[n] 을 정규화한다.) <br>
앞서 입력값 X를 정규화 하는 것이 신경망 학습에 도움을 주었듯이 신경망 안의 깊은 은닉층의 값들까지 정규화해보는 것이다. 이를 통해 은닉 유닛 z의 평균과 분산을 정규화한다.

#### 어떻게 구현할까
신경망에서 사잇값들이 주어졌다고 하자.
어떤 레이어에서 은닉유닉의 값이 z^(1)에서 z^(n)이 있다고 치자.(레이어인 [l]은 생략) <br>
이 값들에 대해서 Normalization 해준다하면 입력값을 Normalization 하였듯이 다음과 같이 할 것이다.
```
평균을 계산
μ = (1/n) * ∑z^(i)

분산을 계산
σ^i = (1/n) * ∑(z^(i) - μ)²

normalize(정규화)를 하여 norm을 구함 (안정성을 위해 ε 추가)
z^(i)_norm = z^(i) - μ / √σ² + ε
```

이렇게 하면 z값에 대해서 정규화를 거쳐 모든 z들의 평균이 0이고 표준편차가 1이 되도록 만들게된다.
하지만 **은닉 유닛은 다양한 분포를 가져야하기때문에 항상 평균0, 표준편차1을 가지는 것은 좋은 일이 아니다.** 그래서 다음과 같이 z~ 을 계산하는 방식을 더 거친다.

```
z~^(i) = γz^(i)_norm + β

```
여기서 γ 와 β는 모델에서 학습시킬 수 있는 변수이다. <br>
경사하강법이나 모멘텀,RMSProp,Adam 등의 다양한 알고리즘을 이용해서 γ 와 β를 학습시킬 수 있다. 신경망에서 w,b를 업데이트했던 것 처럼 말이다. <br>
즉, 은닉 유닛이 표준화된 평균과 분산을 갖되 학습 알고리즘에서 설정할 수 있는 두 변수 γ 와 β에 의해 조절되는 것이다.

### 딥네트워크에 어떻게 사용하는데?

배치 정규화의 정규화 과정에서는 z^[l]의 평균을 계산한 뒤에 빼서 0으로 만들기 때문에 상수 b는 사라진다.

```
Z^[l] = W^[l] * a^[l-1] + b^[l]
```

이것은 곧
```
Z^[l] = W^[l] * a^[l-1]
이 된다.
```
따라서
```
Z^[l] = W^[l] * a^[l-1] 
z^(i)_norm = z^(i) - μ / √σ² + ε
z~^(i) = γ^[l] * z^(i)_norm + β^[l]
```
이 된다. 결과적으로 b의 역할을 β가 차지하게 되었다. <br>
여기서 γ^[l]과 β^[l]의 차원은 은닉유닉층 (n^[l], 1)의 shape와 같다. 은닉유닉의 값을 조정하는데 쓰이기 때문에 같아야겠지? <br>

자, 배치 정규화를 사용하여 미니배치 경사하강법을 구현하는 것을 전체적으로 살펴보자.
- t는 1부터 mini_batch_num까지 반복할 것이다.
    - 미니배치 X^{t}에 대해서 Forward Propagation 실시.
        - 각 은닉층에서 `Batch Normailization` 을 사용하여 미니배치의 평균과 표준편차를 이용, `z^[l]` 을 `z~^[l]` 로 바꿔준다.
    - Back Propagation을 이용하여 dw, dβ, dγ를 계산한다.
    - 각 변수들을 업데이트한다.
        - w^[l] = w[l] - α * dw^[i]
        - γ^[l] = w[l] - α * dγ^[i] 
        - 등등..
물론 모멘텀, RMSPropr, Adam을 이용할 수 있다.

이 `Batch Normailization` 구현은 프레임워크를 이용해서 코드 한 줄로 만들 수 있다.ㅎ

<br><br>

### 왜 도움이 되는데?
은닉층의 입장에선 바로 앞의 은닉층의 값들이 학습을 하면서 계속 변화하기 때문에 공변량 변화문제를 계속 겪게 된다. 

- `Covariate Shift(공변량 변화)`: X, Y 매핑에서 X의 분포가 바뀌면 학습알고리즘을 다시 학습해야하는 것.

여기에 `Batch Normailization` 을 하면 값들의 평균과 분산이 일정하도록 제한을 걸 수 있고, 은닉층 값들의 분포가 변화하는 양을 줄여주어 뒤쪽 층의 부담을 줄여주는 것이다. <br>
또한 앞쪽 층의 파라미터와 뒤쪽층의 파라미터 간의 관계를 약화시킨다. 그래서 신경망의 각 층이 다른 층에 상관 없이 스스로 배울 수 있게 해준다. 따라서 전체 신경망의 학습 속도를 상승시킬 수 있다. <br>

<br>

### Regularization 효과도 덤으로
은닉층에 노이즈가 추가되기때문에 아주 약간의 Regularization 효과를 보여준다. 아주작아서 효과가 크진않다.

### 테스트할 때 주의
배치 정규화는 한번에 미니배치 하나의 데이터를 다룬다. 
하지만 테스트 과정에서는 미니배치가 없을 것이다. 그래서 테스트과정에서는 예측이 잘 맞도록 조금 다른 접근이 필요하다. 어떻게 할 수 있을까~~~는 다음 시간에!

<br><br><br>

# Kaggle
만들어진 모델을 평가할 때 무슨 방법을 쓰면 좋을까? <br>
캐글의 한 노트북에서 모델을 평가하기 위한 방법으로 다음과 같은 방법을 소개해줬다.

<br>

## **Confusion Matrix (오차행렬)**
Classification 모델의 퍼포먼스를 설명할 수 있는 테이블이다. 
간단한 설명을 해보자.

<br>

|   Actual＼Predict   | POSITIVE | NEGATIVE |
|:--------:|:--------:|:--------:|
| POSITIVE |    True Positive    |    False Positive    |
| NEGATIVE |    False Negative    |    True Negative    |

<br>

- `행`은 Actual Values로 실제 값을 말한다.
- `열`은 Predictive Values로 예측값을 말한다.
- `True Positive (TP)`: 모델의 예측도 YES, 실제값도 YES일 때
- `True Negative (TN)` : 모델의 예측이 NO, 실제값도 NO일 때
- `False Positive (FP)` : 모델의 예측이 YES, 하지만 실제값은 NO일 때 (Type 1 에러라고도 부른다.)
- `False Negative (FN)`: 모델의 예측이 NO, 하지만 실제값은 YES일 때 (Type 2 에러라고도 부른다.)

<br>

자, 이제 이것을 가지고 어떻게 분석하는지 살펴보자.

<br>

### **Accuracy**
모델이 예측을 얼마나 잘 예측했는지를 확인
```
TP + TN / total
```
- 이것만 가지고 정확도를 예측할 수 없다.
    - 만약 모델에게 990개의 오렌지와 10개의 사과의 데이터를 주고 사과와 오렌지를 분류하라고 했을 때, 모든 것을 오렌지로만 보는 모델은 정확도가 높을 수밖에 없다. 
    - 즉, 데이터가 편향되어있으면 이 정확도를 신뢰할 수 없게된다.


<br>

### **Misclassification Rate (Error Rate)**
모델이 얼마나 틀렸는지를 확인
```
FP + FN /total
```

<br>

### **Recall (Sensitivity, True Positive Rate, 재현율)**
실제 True인 것중에서 모델이 True라고 예측한 확률
```
TP / TP + FN
```
- 모델에게 사과와 오렌지를 분류하라고 시킨 뒤, **사과클래스에 분류되어있는 사과**를 **전체 사과 값**들로 나눈다고 생각하자.
- 실제로 `Positive` 한 것을 놓치는지 아닌지 확인할 때 씀.
- 잘못된 양성반응은 괜찮지만 양성반응 자체를 놓치는 것은 안되는 의료계에서 중요하게 생각할 확률.
- **Precision** 과는 trade-off 관계이다.

<br>

### **Specificity(True Negative Rate)**
실제값이 True일 때, 모델의 예측값이 False를 한 확률.
```
TN / TN + FN
```

<br>

### **Precision (정밀도)**
모델이 True라고 예측한 것 중에서 실제 True인 것의 확률
```
TP / TP + FP
```
- 모델에게 사과와 오렌지를 분류하라고 시킨 뒤, 모델이 분류한 **사과 클래스 안에 있는 실제 사과 값**들을 **사과 클래스 안에 있는 모든 값**들로 나눈다고 생각하자.
- `Positive` 하다고 말한 것이 실제로 `Positive` 한 것인지를 확인할 때 씀.
- 잘못된 긍정으로 고객에게 안좋은 영향을 끼칠 수 있는 음악, 영상 추천 시스템이나 e-커머스 사이트에서 중요하게 생각할 확률
- **Recall** 과는 `trade-off` 관계이다

<br>

### **Prevalence**
주어진 데이터 샘플에서 모델이 True를 얼마나 많이 했는지를 확인
```
TP + FP / total
```

<br>

### **F1 Score**
**Precision** 과 **Recall(True Positive Rate)** 은 `trade-off` 관계이기 때문에 이를 조화평균해놓은 것.
```
2 * (Precision * Recall / Precision + Recall)
```
- 데이터가 어느 한 쪽으로 치우쳐서 불균형할 때 정확도 대신 쓰인다. 

<br><br>

### **Example**
- `sklearn` 으로 counfusion matrix를 만든 뒤, `pandas`로 직접 볼 수 있다.

```python
import pandas as pd
from sklearn.metrics import classification_report, confusion_matrix

# printing confision matrix
pd.DataFrame(confusion_matrix(y_test,y_pred),\
            columns=["Predicted NO", "Predicted YES"],\
            index=["NO","YES"] )

```

<br><br>

- `sklearn` 으로 바로 예측해볼 수 있다.

```python
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import precision_score

accuracy_score(y_test, y_pred)
recall_score(y_test, y_pred)
precision_score(y_test, y_pred)
```

<br><br><br>

## **ROC Curve (Receiver Operating Characteristic) & AUC Curve (Area Under the Curve)**
**ROC Curve** 는 이진분류에서 클래스별 분포가 다를 때, Accuracy의 단점을 보완하기 위해 사용된다. <br>
다양한 임계값에서 `FPR(1-Specificity)` 에 대한 **`TPR(Recall)`** 값 을 플롯하고 `noise`를 제거하여 `signal`을 얻는 커브이다. <br> 
**AUC Curve** 는 **ROC Curve**의 밑부분을 뜻하며 이 AUC 커브를 이용하여 퍼포먼스를 확인한다. <br>
결과만 말하자면, **AUC Curve**가 높이 향할 수록 `Positive` 와 `Negative` 를 잘 구분할 수 있는 모델인 것이다.

<br>

![](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/06/AUC3.png)

<br>

### 구현

- `sklearn` 으로 간단하게 구현 가능하다.

```python
from sklearn.metrics import roc_curve

# roc curve for models
fpr1, tpr1, thresh1 = roc_curve(y_test, pred_prob1[:,1], pos_label=1)
fpr2, tpr2, thresh2 = roc_curve(y_test, pred_prob2[:,1], pos_label=1)

# roc curve for tpr = fpr 
random_probs = [0 for i in range(len(y_test))]
p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)
```

<br><br>

AUC score도 확인할 수 있다.

```python
from sklearn.metrics import roc_auc_score

# auc scores
auc_score1 = roc_auc_score(y_test, pred_prob1[:,1])
auc_score2 = roc_auc_score(y_test, pred_prob2[:,1])

print(auc_score1, auc_score2)
```

<br>

- `matplotilb` 로 나타낼 수 있다.

```python
import matplotlib.pyplot as plt
plt.style.use('seaborn')

# plot roc curves
plt.plot(fpr1, tpr1, linestyle='--',color='orange', label='Logistic Regression')
plt.plot(fpr2, tpr2, linestyle='--',color='green', label='KNN')
plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')
# title
plt.title('ROC curve')
# x label
plt.xlabel('False Positive Rate')
# y label
plt.ylabel('True Positive rate')

plt.legend(loc='best')
plt.savefig('ROC',dpi=300)
plt.show();
```
![](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/06/ROC.png)


<br><br><br>

### **Multi-Class Classification에서의 AUC-ROC**
`One vs All` 방법을 써서 이진분류에 사용되는 AUC-ROC를 다중분류에 사용할 수 있다. <br>
근데 이건 내가 아직 멀티클래스분류를 안 배워서 봐도 이해가 안가서 나중에 보겠다. <br>
나중에 다시 볼 때 [여기](https://www.analyticsvidhya.com/blog/2020/06/auc-roc-curve-machine-learning/) 를 다시 참조하자.


<br><br><br><br><br>

* * * 
참조
<br>
https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/ <br>
https://www.youtube.com/watch?v=qWfzIYCvBqo <br>
https://www.analyticsvidhya.com/blog/2020/04/confusion-matrix-machine-learning/?utm_source=blog&utm_medium=auc-roc-curve-machine-learning <br>
https://nittaku.tistory.com/297 <br>
https://www.analyticsvidhya.com/blog/2020/06/auc-roc-curve-machine-learning/
