# 코딩테스트 문제풀이
## <이것이 취업을 위한 코딩 테스트다> 책
replit 서버 다운돼서 플로이드 1문제 풀고 그냥 넘어감

<br><br>

# Tensorflow 자격증

## ImageGenerator
현실에서는 Fashion MNIST같이 쉬운 이미지 데이터셋이 주어지지않는다. 좀 더 크고 복잡한 이미지를 CNN에 적용해보자. <br>

먼저, 이미지가 zip파일로 되어있다면 파이썬을 통하여 풀어준다. 아래는 개와 고양이의 이미지일 때의 예시이다.

```python
import os
import zipfile
from os import getcwd

path_cats_and_dogs = f"{getcwd()}/../tmp2/cats-and-dogs.zip"
shutil.rmtree('/tmp')

local_zip = path_cats_and_dogs
zip_ref = zipfile.Zipfile(local_zip, 'r')
zip_ref.extractall()
zip_ref.close()

print(len(os.listdir('/tmp/PetImages/Cat/')))
print(len(os.listdir('/tmp/PetImages/Dog/')))
```

<br><br>

tensorflow가 label을 할 수 있게 이미지의 디렉토리를 만든다. 

```python
try:
    os.mkdir('/tmp/cats-v-dogs')
    os.mkdir('/tmp/cats-v-dogs/training')
    os.mkdir('/tmp/cats-v-dogs/testing')
    os.mkdir('/tmp/cats-v-dogs/training/cats')
    os.mkdir('/tmp/cats-v-dogs/training/dogs')
    os.mkdir('/tmp/cats-v-dogs/testing/cats')
    os.mkdir('/tmp/cats-v-dogs/testing/dogs')
except OSError:
    pass
```

<br><br>

training, test 이미지를 비율에 따라 나눠서 만들어 둔 디렉토리에 복사해준다.
```python
import shutil
from shutil import copyfile


def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):
# YOUR CODE STARTS HERE
    all_files = []
    
    for file_name in os.listdir(SOURCE):
        file_path = SOURCE + file_name

        if os.path.getsize(file_path):
            all_files.append(file_name)
        else:
            print('{} is zero length, so ignoring'.format(file_name))
    
    n_files = len(all_files)
    split_point = int(n_files * SPLIT_SIZE)
    
    shuffled = random.sample(all_files, n_files)
    
    train_set = shuffled[:split_point]
    test_set = shuffled[split_point:]
    
    for file_name in train_set:
        copyfile(SOURCE + file_name, TRAINING + file_name)
        
    for file_name in test_set:
        copyfile(SOURCE + file_name, TESTING + file_name)

CAT_SOURCE_DIR = "/tmp/PetImages/Cat/"
TRAINING_CATS_DIR = "/tmp/cats-v-dogs/training/cats/"
TESTING_CATS_DIR = "/tmp/cats-v-dogs/testing/cats/"
DOG_SOURCE_DIR = "/tmp/PetImages/Dog/"
TRAINING_DOGS_DIR = "/tmp/cats-v-dogs/training/dogs/"
TESTING_DOGS_DIR = "/tmp/cats-v-dogs/testing/dogs/"

split_size = .9
split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)
split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)

print(len(os.listdir('/tmp/cats-v-dogs/training/cats/')))
print(len(os.listdir('/tmp/cats-v-dogs/training/dogs/')))
print(len(os.listdir('/tmp/cats-v-dogs/testing/cats/')))
print(len(os.listdir('/tmp/cats-v-dogs/testing/dogs/')))
```


<br><br>

```python
train_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(300, 300),
    batch_size=128,
    class_mode='binary'
)

test_datagen = ImageDataGenerator(rescale=1./255)

test_generator = test_datagen.flow_from_directory(
    validation_dir,
    target_size=(300, 300),
    batch_size=128,
    class_mode='binary'
)
```
- `rescale=1./255` 을 이용하여 데이터를 normalize해준다.
- `flow_from_directory`를 이용하여 해당 디렉토리와 서브 디렉토리에서 이미지를 로드해준다.
    - 경로는 str이며 흔히 제너레이터를 서브 디렉토리에 지정해주는 실수를 하는데 조심하자. 이미지를 가지고 있는 서브디렉토리가 존재하는 디렉토리를 지정하자.
        - 서브 디렉토리의 이름은 이미지의 `label` 이 된다.
    - `target_size` : 모든 입력 데이터는 같은 크기를 가지고 있어야하므로 크기를 지정해준다. 원본 데이터에 해를 가하지 않으면서 리사이즈를 해준다. 여기서 원본 사이즈보다 이미지를 더 압축해도 된다.
    - `batch_size` : 배치사이즈를 정해준다.
    - `class_mode` : 현재 binary classification 문제를 풀고싶어서 `binary`로 지정해준다. 다음에 더 배울 예정.

<br><br>

## 복잡한 이미지를 사용하기 위한 ConvNet 정의

```python
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(300, 300, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

```

- convolution pooling 레이어가 세 세트로 이루어져있다.
- 컬러 이미지라서 `input_shape` 의 마지막이 3으로 되어있다. 이것은 R,G,B 채널을 뜻한다.
- 마지막은 `sigmoid`로 binary classification에 효율적인 활성화 함수를 사용했다.

<br><br>

## fit_generator 를 이용하여 ConvNet 훈련시키기

```python
from tensorflow.keras.optimizers import RMSprop

model.compile(loss='binary_crossentropy',
optimizer=RMSprop(lr=0.001),
metrics=['acc']
)

```

- binary 선택을 하기 때문에 loss 함수를 `binary_crossentropy` 로 선택했다.
- `Adam` 대신 `RMSprop` optimizer를 사용해보자.

<br>

```python
history = model.fit_generator(
    train_generator,
    steps_per_epoch=8,
    epochs=15,
    validation_data=validation_generator,
    validation_steps=8,
    verbose=2
)
```

- 위에서 만들었던 `train_generator` 을 사용해준다.
- 위에서 batch size를 128으로 만들었었다. 따라서 학습 디렉토리에 있는 1,024개의 이미지가 128개씩 로드될 것이다. 모두 로드하고싶으면 batch를 8로 해줘야한다.
- 학습 epoch를 설정한다. 여기서는 15로 설정했다.
- 위에서 설정한 validation_data를 입력해서 학습할 때 validation set의 정확도도 같이 볼 수 있다.
- history를 이용하여 모델의 히스토리로 accuracy등을 확인해볼 수 있다.
- model.layers API를 이용하여 이미지에 대한 convolution들의 영향을 볼 확인해볼 수 있다.
<br><br>

이제 이미지를 예측해보자.

<br>

```python
import numpy as np
from google.colab import files
from keras.preprocessing import image

uploaded = files.upload()

for fn in uploaded.keys():
    # predictig images
    path = '/content/' + fn
    img = image.load_img(path, target_size=(300, 300))
    x = image.img_to_array(img)
    x = np.expand_dims(x, axis=0)

    images = np.vstack([x])
    classes = model.predict(images, batch_size=10)
    print(classes[0])
    if classes[0] > 0.5:
        print(fn + ' is a human')
    else:
        print(fn + ' is a horse')

```

<br><br>

## Augmentation

```python
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)
```
- `rotation_range` 는 0~180까지 있다.
- `shear_range` skewing이다.
- `fill_mode` 로 augmentation에서 잃을 수 있는 픽셀을 어떻게 채울 것인가를 정한다.

image augmentation 은 train set에 무작위로 정보를 더 해주지만 테스트 셋에서는 그러한 무작위 정보가 제공되지않아 결과가 안 좋을 수 있다.

<br><br>

coursera 노트북이 자꾸 에러를 뱉어서 그거 해결한다고 시간 잡아먹어버린 것이 안타깝고만.