# ML
# Coursera - Sequence Models - Sequence Models & Attention Mechanism
# Various Sequence To Sequence Architectures

## Basic Models
기계번역이나 음성인식에 잘 사용되는 sequence to sequence 모델을 알아보자.

### Sequence to sequence model
프랑스어를 영어로 번역해주는 모델을 만든다고 생각해보자. 그 모델은 다음과 같이 생겼을 것이다.

<br>

![Sequence to sequence model]()

- 인코딩 망
    - 인코더망을 RNN 구조(GRR, LSTM)로 만든다.
    - 번역하고자 하는 단어를 하나씩 입력한다.
    - 입력 문장을 나타내는 벡터를 출력한다.
- 디코더 망
    - 한 단어씩 번역하여 출력하도록 학습한다.

### Image captioning
위에서 본 아키텍쳐와 비슷한 것은 이미지 캡션하는 것에도 잘 작동한다.

<br>

![Image captioning]()

- pre-trained된 CNN(여기서는 AlexNet)을 인코더로 쓴다.
- 마지막 소프트맥스는 제외하고 이미지를 나타내는 4096의 벡터를 가진다.
- 그 벡터를 RNN에 넣고 한 단어씩 캡션을 생성한다.

<br><br>

## Picking the Most Likely Sentence
sequence to sequence 기계번역 모델과 language model은 비슷한 것 같아 보이지만 다른점이 있다. 그것을 한 번 보자. <br>

### Machine translation as building a conditional language model

![Machine translation as building a conditional language model]()

- `Language Model`
    - language model은 문장의 probability를 추정할 수 있게 해준다.
    - 문장을 랜덤하게 생성한다.
    - 문학 문장을 생성해줄 수 있다.
- `Machine translations`
    - 인코더와 디코더가 있다.
    - 디코더가 language 모델과 비슷하다.
    - 번역하고 싶은 언어 문장에 따라 번역 문장의 probability를 추정할 수 있게 해준다.
- `Machine translations` 모델과 Language 모델은 언제나 모든 것이 0인 벡터로 시작하는 것을 빼면 굉장히 비슷한 것을 볼 수 있다.

### Finding the most likely translation

![Finding the most likely translation]()

기존의 `p(y^<1>, ..., y^<Ty> ｜ x)` 의 분포에서 단어를 sample하면 한 타임에선 괜찮은 문장을 얻을 수 있을지 몰라도 다른 타임에서는 다른 번역을 얻어서 이상한 문장을 얻을 수 있다. 해당 언어에 맞는 문장을 생성해야하는데 랜덤한 문장을 출력하고 있는 것이다. 그래서 conditional probability를 최대로 하는 영어 문장 y를 찾아야한다. 이를 할 수 있는 잘 알려진 알고리즘이 바로 `beam search 알고리즘`이다. 

### greedy search를 쓰면 안되나?
굳이 beam search 알고리즘 말고 greedy search라는 것을 쓰면 안되는가? <br>
greedy search는 첫번째 단어를 선택할 때, 최고의 확률을 가지는 단어를 선택하고 그런 방식으로 냅다 두번째에 올만한 것을 찾고 냅다 세번째에 올만한 것을 찾는다. 이러한 것은 사전의 모든 것을 다 뒤져야해서 자원도 많이 들고 또한 일반적으로 자주 사용되는 단어로만 번역하려는 성향을 가지게 되어서 실제로는 번역이 잘 되지도않는다.

<br><br>

## Beam Search
"제인이 9월에 아프리카를 방문한다."는 프랑스 문장을 영어 문장 "Jane visits Afica in September." 로 번역하고 싶다고 해보자. 사전의 크기는 10,000이다.

![Beam search algroithm step1]()

- 인코더망에서 소프트맥스에 의한 모든 10,000의 가능성을 출력한다.
- 이 10,000의 가능성 출력들을 가지고 영어 문장의 첫 단어를 선택하는데 이 때, 가능성이 높은 몇몇의 단어를 메모리에 저장한다.
    - `P(y^<1> ｜x)` 의 가능성을 평가할 때, `B (beam width)` 라고 하는 파라미터를 통하여 몇몇 가능성이 높은 단어들을 `B`의 수에 따라 메모리에 저장해놓는다.
    - e.g) `B`는 3으로 정의해서 첫번째 단어로 in, jane, september을 선택.

<br>

![Beam search algroithm step2]()
- 선택한 각각의 단어에 대해 두번째 단어가 무엇인지 10,000개의 가능성을 고려한다.
    - 각각의 단어는 `P(y^<1>, y^<2> ｜x)` 를 통해 앞의 단어와 **쌍을 이루어** 가능성을 평가한다.
- 고려한 30,000개의 가능성 중에 또 가능성이 높은 몇몇의 단어를 메모리에 저장한다.
    - e.g) `B`는 3으로 정의해서 두번째 단어로 in-september, jane-is, jane-visits을 선택.
        - 이 때, 첫번째 단어의 가능성을 가지고 있던 september은 후보에서 제외됨.

<br>

![Beam search algroithm step3]()

- 앞의 두 단어를 이용해서 세번째 단어의 가능성을 10,000개의 가능성 평가한다.
- `P(y^<3>｜x, "in september")`
    - 쭉 <EOS>가 나올 때 까지 한 단어씩 이것을 반복한다.

<br>

`B` 가 1이면 위에서 봤던 greedy 알고리즘이 될 것이다.

<br><br>

## Refinements to Beam Search
지금까지 기본 Beam search algroithm을 보았다. 이걸 살짝만 바꿔서 좀 더 성능을 좋게 해보자. <br>

### Length normalization
Length normalization은 beam알고리즘을 좀 더 나은 결과를 볼 수 있게 바꾼 것이다. 

![Length normalization]()

beam 알고리즘으로 P를 계산해보면 모든 숫자의 확률이 1보다 작다(종종 훨씬 작아짐). 이것들을 다 곱하면 정말 작은 숫자가 되는데 이것은 저장하기에 너무 작음을 뜻하는 수치적 underflow를 야기시킨다. <br>
그래서 실제로는 곱연산이 덧셈으로 전환되는 log를 취해서 수치적으로 안정적인 결과를 받을 수 있게하고 1/T_y를 이용하여 normalize해줘서 각각의 단어의 평균을 받게함으로써 긴 문장에 대한 패널티를 줄일 수 있다. normalize할 때, alpha를 이용해 normalization을 조정할 수 있게할 수 있다.

<br>

### Beam search discussion
- `B` 가 클 때
    - 좋은 결과가 나오지만 느리다.
- `B` 가 적을 때
    - 결과가 좋진않지만 빠르고 메모리도 적게든다.
- 실제 상업 어플리케이션에서는 `B`를 10정도로 쓴다.

<br><Br>

## Error Analysis in Beam Search
Beam 알고리즘은 항상 가능성 있는 문장을 출력해주진 않는다.
에러가 일어났을 때, Beam 알고리즘의 문제인지 RNN모델의 문제인지를 빨리 알아낼 수 있도록 에러를 확인하는 방법을 알아보자. <br>

- RNN이 P(y｜x)를 계산하는 것을 이용해서 P(y*｜x), P(y^｜x) 을 계산하고 둘 중 어느것이 큰지 본다.
    - `y*` : 사람이 예측한 최적의 예측

- P(y*｜x) > P(y^｜x)
    - Beam search 알고리즘이 y^을 선택했지만 y*가 더 높은 가치를 지니고 있다.
    - Beam search가 실패했다는 것을 알 수 있다.
- P(y*｜x) ≤ P(y^｜x)
    - y*가 y^보다 더 번역을 잘했는데도 RNN이 y^가 더 출력될 가능성을 더 가지고 있다고 예측했다.
    - RNN모델이 실패했다는 것을 알 수 있다.

<br><br>

## Attention Model Intuition
지금까지 인코더/디코더를 구조를 살펴보았다. 이것을 조금 수정해서 조금 더 발전시킨 attention 모델을 알아보자. <br>
여태까지 인코더는 모든 문장을 읽고, memorize한 뒤 activation에 store했다. 그리고 디코더는 영어번역을 생성했다. 이러한 구조는 모든 문장을 다 기억해야하기때문에 문장이 길면 길어질수록 성능이 떨어지게된다. <br>
그래서 사람처럼 문장의 부분 부분을 보고 번역하는 attention model이 나오게된다. 앤드류 응은 이것이 딥러닝계에 영향력이 있다고 생각한다.
<br>

### Attention model

![Attention model intuition]()

- Bidirectional RNN을 사용한다.
- forward only RNN을 stack한다.
- forward only RNN 의 첫번째 아웃풋은 어떤 정보에 집중해야할까?
- Bidirectional RNN에 추가한 `attention weights(α)` 가중치를 모두 종합(c)하여 어떤 정보에 얼마나 집중해야할지를 정한다.

<br>

![Attention model]()

<br>

그럼 여기서 어떻게 `attention weights(α)` 를 정할까? 걱정마시라. 논문에 식이 있다.<br>

![Computing attention a]()
- 여기서 e는 작은 신경망을 만들어서 계산한다.
<br>
계산비용이 많이 들긴하지만 부분적으로 계산하기 때문에 할 만하다. 이미지 캡션에도 사용가능하다.

<br><br>


# Coursera - Sequence Models - Speech Recognition - Audio Data
## Speech Recognition
Sequence to Sequence 모델이 어떻게 오디오 데이터에 적용될지 한 번 보자. 

### Speech Recognition 문제
Speech Recognition 에 대한 문제는 audio clip이 인풋으로 주어지면 text로 변환한 y를 출력해야하는 것들이 것이다. <br>
Attention 모델, CTC모델을 쓸 수 있을 것이다.
