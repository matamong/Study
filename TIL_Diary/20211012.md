# Self-training with Noisy Student improves ImageNet classification

<br>

EfficientNet과 CatBoost를 이용한 노트북을 쭉 보는데 다음과같은 개념을 사용하고있어서 한 번 살펴봤다.

<br>

![](https://hoya012.github.io/assets/img/noisy_student/1.PNG)

<br><br>

## **Self-training**
이름 그대로 자기 학습을 하는 것으로, 모델 자신이 예측한 것 중 높은 확률값이 나오는 데이터를 취해서 다시 학습하는 것.`semi-supervised learning technique`이다.
- labled data를 가지고 모델을 학습
- 이 모델로 unlabled data 예측
- 예측한 것 중에 가장 확률값이 높은 데이터들을 labled data로 취함
- 과정 반복

간단하고 어떤 알고리즘이라도 적용가능하지만 초반 예측이 잘못되면 계속 잘못학습할 수 있음.


<br><br>


## **Noisy Student**
SOTA 모델에 라벨링되지않은 이미지를 사용해서 성능을 향상시키는 것. 
- Teacher 모델에 ImageNet 데이터 학습
- 학습된 Teacher모델로 unlabled data에 labeling
- Student 모델을 Teacher모델보다 크거나 같은 사이즈로 생성한 뒤, Student모델에 ImageNet 데이터와 labeling된 데이터를 학습시킴
    - 이 때, `RandAugment`, `Dropout`, `Stochastic Depth`로 Noise를 줌.
        - `Stochastic Depth` : 훈련 중에 ResBlock을 **무작위로 삭제하고 건너뛰고 연결하는 것**으로 훈련 중에 **신경망의 깊이를 줄이기 위한 방법**의 하나다. 테스트 중에는 깊이를 변경하지않고 유지한다. 
- 이렇게 학습한 Student 모델을 teacher 로 잡고 다시 labeling 과정부터 반복.

이렇게 함으로써 성능을 끌어올릴 수 있다.

<br><br><br><br>

# Pytorch 모델 저장 & 불러오기

## weight
```
torch.save(model.state_dict(), 'weights_only.pth')

model_new = NeuralNet() 
model_new.load_state_dict(torch.load('weights_only.pth'))
```
- 설정한 모델의 구조는 불러올 수 없다.

<br>

## 전체
```
torch.save(model,'entire_model.pth')

model_new = torch.load('entire_model.pth')
```
- 설정한 모델의 구조도 불러올 수 있다.


<br><br><br><br>

# 한국어 형태소 분석기 
한국어 toxicity를 구분하기 위해서 자료를 찾아봤으나 별로 없었음. 그나마 네이버 영화리뷰 0점짜리들을 이용할 수는 있었는데 toxic하다기보단 비평 text가 많았다. 감정분석에 어울리겠지만 나는 toxicity를 원하니까 
[korean-hate-speech](https://github.com/kocohub/korean-hate-speech)
를 이용하기로 했음. (감정분석에서 toxicity 분석을 하고싶었음.)
- huggingface에서 한국어 BERT pre-trained 모델불러오기
- AutoTokenizer 이용해서 tokenizing

<br><br><br><br>

#

오픈소스 contributer 분들에게 너무 감사한 하루였다. 그만큼의 데이터를 모으기도 힘든데 그만큼의 모델을 돌릴 수 있는 비용도 없지만 오픈소스 기여자분들 덕분에 그래도 각이 나오는 듯 하다.

<br><br>

* * * 
https://towardsdatascience.com/efficient-nets-with-noisy-student-training-5ac6e239ff14 <br>
https://paperswithcode.com/method/stochastic-depth <br>
https://jayhey.github.io/semi-supervised%20learning/2017/12/07/semisupervised_self_training/ <br>
https://www.youtube.com/watch?v=P0fyKb3U9yo <br>