# ML
# Coursera - Structuring Machine Learning Projects
## Error Analysis
프로젝트에 오류가 많으면 수정해야할 것이다. 오류수정을 어떻게 파악하고 잘 할 수 있을지 알아보자.

<br>

### Carrying Out Error Analysis
- Error analysis
    - 10% 까지의 잘못 분류된 dev(valid) set을 뽑는다.
    - 잘못분류된 것들 중 맞는 것의 확률을 본다.
    - 맞는 것의 확률이 높은 것을 수정한다.


너무 핸드엔지니어링이긴 하지만, 알고리즘이 잘못 카테고리화한 `dev_set_sample` 을 봄으로써 앞으로 해야할 수정작업이 얼마나 값어치를 하는지를 파악할 수 있다. <br>
이 방식을 주루룩 피쳐별로 나열해서 중요순위를 뽑을 수도, 그 과정에서 새로운 수정작업을 발견할 수도 있다. <br>
그러나 `dev_set`을 보면서 하는 작업인데 `dev_set` 이 올바르지 않다면? 다음으로 넘어가보자.

<br>

### Cleaning Up Incorrectly Labeled Data
데이터가 결과적으로 잘못 레이블되었다면, 이런 레이블을 수정하는데 값어치가 있을까?

#### Train_set 의 경우.
- `train_set` 에서 몇개의 실수같은 미스레이블링, 즉 랜덤에러가 날 경우엔 충분히 머신러닝이 견딜 수 있긴하다. 물론 고치는게 좋긴하지만 다시 뜯어고치는 것에 자원이 더 쓰여질수도.
    - 대신 `systematic error` 에는 약하다. 지속적으로 미스레이블링된 것들은 고쳐야함.

<br>

#### dev_set / test_set 의 경우
오류 분석 중 레이블이 틀린부분을 위에서 했던 Error Analysis을 이용해서 잘못 레이블되었다고 코멘트를 남기면서 기록을 해보자. 그리고 확률을 보고 값어치가 있는지 확인하는 것이다.
- 만약, 전체 dev_set 에러중에 비중이 높아 개선해야할 값어치가 있다고 판단되면 시간을 써서 고치자.
- 하지만 전체 dev_set 에러중에 비중이 높지 않아 성능이 크게 바뀌지 않는다면 시간을 많이 쓰기 때문에 포기하자.

<br><br>
수동 엔지니어링이긴 하지만 해서 나쁠 건 없으니까 데이터를 직접적으로 보라는 앤드류 응의 조언.

<br><br>

### 첫번째 시스템을 먼저 빨리 만들고 반복해라!
만약에 새 어플리케이션을 만들려면 먼저 빨리 만들고 반복해라! 
<br>
잘 작동하는 머신러닝을 만들 목적이라면 처음부터 복잡하게 만들지말라는 앤드류 응의 조언.

#### 구체적으로 무슨 말인디?
- `dev(valid)/test` set을 셋업해라.
- 머신러닝시스템을 빠르게 만들어라.
    - train 하고 test 해라.
- 편향/ 편차 분석과 Error Analysis 를 이용해서 수정작업의 우선순위를 만들어라.

<br><br><br>


## Mismatched Training and Dev(Valid)/Test Set
`train` 과 `dev/test` set이 다르다면 어떻게 할까?

<br>

### Training and Testing on Different Distributions
일부 혹은 많은 데이터가 각각 set에 같은 분포로 나오진 않을 수 있다. 대처를 어떻게 해야할까? 고양이 분석모델에서 웹페이지에서 긁은 고화질 고양이사진과 모바일에서 사용자가 제출한 흐리고 아마추어적인 고양이사진 중 우리는 사용자가 실제로 사용할 수 있는 모바일 사진을 더 맞추고 싶기 때문에 모바일 사진을 더 많이 이용하고 싶을 것이다. 그런데 모바일 사진이 많이 없을 때? 이럴 때 셔플을 하여 배분할 순 있겠지만, 셔플을 해도 dev set은 90%가 고화질 사진이고 10%만이 모바일 사진이 되기 때문에 대부분의 시간을 고화질 사진을 최적화하는데 쓰일 것이다. 이것은 우리가 원하는 것이 아니다. 대신 앤드류 응은 다음을 추천해줬다.

<br><br>
고화질 고양이 사진이 200,000개, 모바일 고양이 사진이 10,000개라고 치면

- `trian_set` 에 고화질 고양이 사진 200,000개의 사진을 때려박는다. 원한다면 5000개의 모바일 사진도 집어넣는다.
- `dev/test_set` 에 모바일 사진을 다 집어넣는다.


<br><br>

### Bias and Variance with Mismatched Data Distributions
우리가 가진 데이터를 다 훈련과 테스트에 쏟아 부어야할까? <br>
Bias와 Variance를 예측하는 것은 방향성을 정하는데 도움을 준다. 그런데 `training` 세트가 `dev(valid)/test` 세트와 비교하여 분포도가 다를 경우에는 Bias와 Variance를 분석하는 방법이 달라진다. <br>

- training set error와 dev set을 합친 `training-dev` set을 만들어서 학습엔 사용하지않고 테스트헤서 에러만 확인해본다.
- `training-dev` set의 에러를 `training` set의 에러와 비교하고, 그것을 **varience** 문제라고 정의한다.
- `training-dev` set 에러와 `dev(valid)` set 에러를 비교하는 것은 **`data missmatch`** 문제라고 정의한다.
- `test` set 에러와 `dev(valid)` set 에러를 비교하는 것은 overfitting 문제라고 정의한다.
    - dev와 test 셋은 분포도가 같기 때문에 dev 셋에서 훨씬 더 잘 작동하는 경우라면 dev 셋에 오버피팅되어있다는 이야기이다. 따라서 dev 셋의 데이터들 더 수집하는 것이 방법이다.

<br>

위와 같은 경우 일반적으로 에러의 확률은
- training set 
- train-dev set 
- dev set 
- test set
순으로 점점 올라간다. <br>
<br><br>

### Addressing Data Mismatch

와오 이제 편향과 분포에 대한 문제뿐만아니라 데이터미스매치에 대한 문제까지 생겨버렸다. 데이터미스매치는 어떻게 해결할 수 있을까?

#### Addressing data mismatch
- error analysis로 `train`과 `dev/test` 의 차이점을 이해하려고 노력할 수 있다.
- `dev/test` 데이터 셋과 비슷한 `train` 데이터를 더 추가해본다.
- 인공 데이터 합성(Artificial data synthesis) 와 같이 인공적으로 데이터를 합성해볼 수도 있다.
    - 잘못 합성한 데이터로 인해 오버피팅 문제가 일어날 수 있기 때문에 주의해야한다.

<br><br>


## Learning from Multiple Tasks

### Transfer Learning

신경망 네트워크에서 고양이같은 것을 인식하게만들고 그 부분적인 지식을 이용해 x-ray스캔을 읽는 것에 적용해볼 수 도있다. 이런 것을 `Transfer Learning` 이라고 부른다. 대부분 데이터가 많고 해결하려고 하는 데이터가 적을 때 쓰일 수 있다.(반대일 때는 별 의미가 없다.)<br>
어떻게 적용해볼 수 있을까? <br>

- 마지막 층의 출력 부분을 꺼내고, 새로운 결과값 노드를 만들어야한다.
    - 새로운 층을 생성하는 것도 가능한다.
- 마지막 층의 `W` 를 랜덤하게 초기화 시키고 새로운 데이터세트로 다시 학습시킨다.
- 데이터의 크기에 따라 마지막 층만 초기화 시킬지 전체 층을 초기화 시킬지를 결정한다. 
    - 모두 초기화 시키고 재학습하기 전의 경우, `pre-traning` 이라고 부르기도 한다.
    - 재학습이 다 이뤄졌을 경우 `fine-tuning` 이라고 부르기도 한다.
<br>
이러한 것이 가능한 이유는 모델이 이미지에대한 로우레벨 지식(선, 점, 곡선등등)을 익혔기 때문이다.  <br>

#### 언제 쓸 수 있을까?
A에서 B로 이전시킨다고 생각했을 때,

- A, B가 같은 input x를 가졌을 때.
    - 이미지, 오디오와 같이 같은 input x를 가져야한다.
- A의 데이터가 B보다 많을 때.
- A업무의 로우레벨 피쳐들이 B업무에 도움이 된다고 생각될 때.

<br><br>

### Multi-task Learning
`Transfer Learning` 이 하나의 작업에서 학습을 하고 다른 작업으로 넘어가는 것이라면, `Multi-task Learning` 은 복수의 작업에서 학습을 하는 것이다. <br>
하나의 이미지에 여러개의 레이블을 붙이는 것과 같다. <br> 레이블이 잘못되어 예측값을 모르는게 있어도 학습을 계속 할 수 있는 장점이있다.

#### 언제 할까?
- 로우레벨 피쳐를 공유하고 있을 때
    - 자율주행차의 신호등, 차량, 보행자를 인식하는 것은 정지신호를 인식하는 피쳐와 비슷하다.
- 작업을 하는 데이터가 비슷할 때 (항상 그래야하는 건 아니다.)
- 큰 신경망을 잘 훈련시킬 수 있을 때

<br>

트렌스퍼가 훨씬 더 많이 이용된다. 멀티테스크는 엄청나게 커야하기때문에 덜 쓰이긴하는데 CV에서 여러개를 캐치해야할 때 쓰이긴 한다.

<br><br>

## End to End Learning
단계를 쪼개서 많은 단계를 한번에 수행하는 것.
<br>
- 여러 수행을 거칠 때 드는 데이터보다 하나씩 쪼개서 수행할 때 데이터가 충분할 수 있다.
<br>

### 언제 써야하는가요?

#### End to End의 장단점
- 장점
    - 데이터가 알아서 흘러간다.
    - hand-desigining을 적게 할 수 있다.
        - 설계 작업 흐름을 단순하게 할 수 있다.
- 단점
    - 데이터가 많이 필요하다.
    - hand-desigining을 적게 할 수 있다.
        - 직접 설계할 수 가 없다.

<br>

#### End to End 적용
- 충분한 데이터가 있는가가 제일 중요하다.

<br><br>

# Coursera - Convolutional Neural Networks
## Convolutional Neural Networks
### Computer Vision
CV 를 안한다고해도 여기서나온 아이디어들은 다른 곳에 쓸만한게 많다. <br>
CV는 입력값이 크다.


#### Computer Vision 유형들
- Image Classification
- Object detection
- Neural Style Transfer

#### Computer Vision이 맞닥뜨리는 문제
이미지 하나만 해도 1000*1000*3이면 매트릭스가 어엄청나게 커진다. 그래서 신경망을 효율적으로 구성해야한다.

### Edge detection example
모서리 감지를 통해 합성곱이 어떻게 작동하는지 살펴보자.<br>

#### Vertical edge detection
신경망은 가로축과 세로축을 감지한다. 어떻게 감지할까? <br>
예를들어 세로축을 감지한다고하면 다음과 같이 인지한다.

<br>

- 6*6 그레이 스케일이 있다고 해보자
- 3*3의 필터를 만든다.
- 그레이스케일을 필터로 합성곱해준다.
- 결과로 4*4의 행렬(이미지)이 나온다.
- 4*4의 결과를 계산한다.
    - 첫번째 요소를 계산하는데 이것은 3*3필터를 가지고 원래 이미지(6*6)의 윗부분에서 3*3영역에 놓는다.
    - 여기서 `element-wise` 곱을 해준다.
    - 그렇게 나오는 9개의 숫자를 더해준다.
    - 그러면 숫자가 나오는데 그것을 첫번째요소에 넣어준다.
    - 다음 요소를 계산하려면 똑같은 방법이지만 한칸씩 옮겨서 실행한다.

이런 식으로 감지한다. <br>
그레이스케일의 명암과 준비된 필터를 합성곱하여 나온 결과를 통해 이미지의 수직경계선을 찾을 수 있게 해주는 것이다.

<br>

#### 양과 음의 윤곽선의 차이 감지(서로다른 밝기전환)
만약 위의 이미지 뒤집어서 10들이 오른쪽에 있고 0이 왼쪽에 있을 때, 같은 필터로 합성곱을 하면 -30들을 얻는다. <br>
이러면 어두운 곳에서 더 어두운 곳으로 가게 된다.

#### Learning to detect edges
딥러닝이 발전하면서 어떤 복잡한 이미지에서 윤곽선을 검출하려고 할 때, 필터의 9개의 숫자를 일일이 고를 필요가 없을 수 있게되었다. 스스로 학습하게 두고 9개의 숫자를 아예 변수로 설정한 다음 역전파형식으로 학습을 시키는 것이다.

<br><br>

더 나아가기 전에 합성곱신경망을 변형하는 방식을 살펴보고 합성곱 신경망의 기본 구성요소가 이렇구나를 알아보자.

<br><br>

### Padding
합성곱 신경망을 변형하는 방식 중 하나이다. <br>
위에서 봤던 합성곱을 보면 
- 6*6 을 3*3과 합성곱하면 4*4가 되었다. 6*6에 대응하려면 3*3 필터를 써야하기 때문이다.
이를 일반화해보면
- n*n를 f*f와 합성곱하면 n-f+1 * n-f+1 이 되는 것이다.

이 방법은 두 가지 단점이 있다.
- 합성곱 연산을 할 때마다 이미지가 축소된다. (Shirinking output)
    - 딥러닝에서 수백개의 층에서 윤곽을 관찰했다면 이미지는 쪼그라들고말것이다.
- 가장자리나 코너에 있는 픽셀은 결과이미지에 덜 사용될 수 밖에 없다.

이를 해결하기 위해서는 합성곱 연산을 하기 전에 덧대는 것이다.(Padding) <br>
즉, 6*6 이미지가 있다고 치면 1px만큼 가장자리를 더해주어 8*8 이미지를 만들어주고 이것을 기존 3*3 필터와 합성곱을 하면 6*6이미지를 얻는 것이다. 여기서 0을 덧대는 것이 일반적이다. <br>
만약, p가 패딩의 양이라면 결과는 패딩을
- n+2p-f+1 * n+2p-f+1
이 되는 것이다. <br>
이렇게 하면 가장자리의 정보를 더 사용할 수 있다. 

<br><br>

#### 패딩하는 법
##### Valid and Same Convolution
- Valid Convolution (유효 합성곱)
    - 위에서 합성곱을 처음 했던 것 처럼 패딩이 없는 것
    - 이미지가 n*n, 필터가 f*f이라 치면 결과는
        - n-f+1 * n-f+1
- Same Convolution (동일 합성곱)
    - 패딩을 해서 결과 이미지의 크기가 기존 이미지와 동일하게 하는 것.
    - 이미지가 n*n, 필터가 f*f, p가 패딩이라 치면 결과는
        - n+2p-f+1 * n+2p-f+1

일반적으로 CV에서 f는 홀수이다. 짝수의 필터를 거의 볼 수 없다. 홀수가 더 사용하기 좋음 보통 3*3이 많이 사용된다. <br>

<br><br>

### Strided Convolutions
stride를 설정한다는 것은 결과를 계산할 때 필터를 이미지에서 얼마나 옮기는가를 이야기한다. 예를 들면, 위에서는 stride를 1로 뒀던 것이다. <br> 
stride를 2로 두고 7*7 이미지를 3*3 필터로 합성곱하면 3*3 결과를 얻는다. 이를 통해 입력과 결과의 크기는 다음과 같이 공식을 세워 얻을 수 있다.
```
패딩을 p만큼 한 이미지 n*n 을 필터 f*f 로 합성곱하는데 stride를 s로 주면
(n+2p-f / s + 1) * (n+2p-f / s + 1)

```
이 때, 값이 정수가 아니라면 내림(┗┛)해준다.(필터를 이미지에 댔을 때, 필터가 밖으로 삐져나가면 계싼을 안한다. 그래서 일반적으로 필터가 이미지에 딱 맞게 설정한 뒤에 결과를 계산해주는 관습이 있다. 그래서 계산할 때 내려준다.) 

<br>

#### 수학에서 정의하는 합성곱과의 차이를 조금만 알아보자.
- 수학
    - 수학에서 이미지와 필터를 합성곱 하라고 하면 합성곱 하기 전에 필터의 가로와 세로축을 뒤집을 것이다.
- 딥러닝에서의 합성곱 연산
    - 수학에서 뒤집는 것을 안하고 그냥 합성곱한다. 
    - 그래서 사실은 교차상관(cross-correlation)이라고 해야하는건데 그냥 관습적으로 합성곱이라고 부르는 것이다ㅋ

<br><br>

### 입체형태에서의 합성곱
2D 이미지가 아니라 3D 입체에서의 합성곱을 알아봦!

<br>

#### Convolutions on RGB images
이미지가 6*6이라고 하면 컬러일 경우 6*6*3 (RGB가 들어가니까) 이 될 것이다. 이 이미지의 윤곽선 검출이나 다른 특성을 알아보려면 이전의 3*3필터 대신 3D필터를 사용한다. 즉, 3*3*3 (RGB) 의 필터를 사용하는 것이다.  <br> 이것을 다음과 같이 표현한다.
```
height * width * channels
** channel 은 이미지와 필터 둘 다 똑같아야한다.
```
이것을 이용해 다음과 같이 결과값을 계산할 수 있다.


이 합성곱의 결과를 계산하기 위해서는 이 입체적인 3*3*3 필터를 이미지의 왼쪽 위에 위치하게 만들어줘야한다.
- 3*3*3 필터의 모든 27개의 숫자를 각각 빨강, 초롱, 파랑 채널의 이미지의 해당하는 수와 곱해준다.
- 이것으로 결과 이미지의 첫 숫자를 얻을 수 있다.
- 다음으로 정육면체를 옮겨서 쭈욱 같은 방식으로 계산해준다.

<br>

빨간색 채널의 윤곽선을 검사한다고 치자. 첫번째 필터는 갖춰져있지만 초록,파란색 채널은 전부 0이 될 것이다. 이 세가지가 합쳐져서 3*3*3 필터를 이루면 빨간색 채널의 세로 윤곽선만 검사하게될 것이다. 이런 식으로 모든 윤곽선을 검출할 수 도 있다. 즉, 3*3*3 필터에 값들을 달리해주면서 다른 특성들을 검출할 수도 있는 것이다. <br>
6*6*3 이미지를 3*3*3의 필터와 합성곱하면 필터의 값이 적용된 4*4 2D 요소가 나오는 것을 알아두자.

#### Multiple filters
이때까지 계속 Vertical만 봤는데 만약에 우리가 수직말고 세로, 가로 둘 다 보고싶거나 45도같이 기운 것까지 검사하고싶다면? <br>
- 만약에 6*6*3 이미지가 있고 3*3*3 수직 필터를 합성곱해서 4*4 의 이미지를 결과로 냈다고 치자.
- 수평도 알고싶다면 6*6*3 이미지에 3*3*3 수평 필터를 합성곱한 4*4의 이미지를 기존 수직 필터를 합성곱한 결과 뒤에 쌓는다.
- 결과적으로 4*4*2의 크기를 가진 결과가 생긴다.

<br><br>

### One Layer of a Convolutional Net
합성곱 신경망의 한층을 알아보자! <br>
위에서 했던 RGB 합성곱을 합성곱 신경망 층으로 만들기 위해서는 쌓기 전에 각각의 결과이미지에 bias(편향, 실수, e.g ReLu같은..)를 더해주는 것이다. 그렇게 한 뒤 쌓아주면 합성곱 신경망의 한 층이 된다. WOW <br>

전방향전파의 한스텝은 다음과 같았다.
```
z^[l] = w^[l]a^[0] + b^[l]
a^[l] = g(z^[l])
```
이제 저 식에서 기존 이미지의 값들이 a가 되고 필터의 값들이 w가 되는 꼴이다 WOW<br> <br>

#### 한 레이어에 파라미터수는 얼마나 들어갈까?
신경망의 한 레이어에 3*3*3 으로 되어있는 필터가 10개 있다고 생각하자. 이 레이어는 파라미터를 얼마나 가지고 있는 것일까? <br>
- 3*3*3 의 숫자들 27개
- bias 1개
- 이것들이 10개 있으니까 280개
여기서 알 수 있는 것은 아주 큰 1000*1000같은 이미지가 들어온다고 하더라도 적은 수의 변수로 대응이 가능하다는 것이다.

<br><br>

### Simple Convolutional Network (ConvNet) Example
싱글레이어를 봤으니 딥 컨볼루셔널 네트워크를 한 번 살펴보자. <br>
인풋이 있으면 필터와 stride, padding의 값에 따라 계속 레이어를 거치고, 마지막 입체 결과값을 쫙 펴서 벡터로 만든 뒤, 로지스틱회귀나 소프트맥스를 적용하여 인식을 하게되는 것이다. <br>
여기서 중요한 점은 입체적인 결과값을 벡터로 쫙 편다는 것이다. <br>
일반적으로 신경망이 계속 될 수록 크기는 줄지만 채널의 수는 느는 경향을 볼 수 있다.  <br>
일반적인 합성곱 신경망은 세 종류의 레이어가 있다.
- 합성곱 레이어 (CONV)
    - 우리가 지금까지 했던 레이어
- Pooling (POOL)
- Fully conneted (FC)

<br><br>

### Pooling Layers
표현 크기를 줄임으로써 계산 속도를 높이고 특성을 훨씬 더 감지할 수 있다. <br>

#### Pooling 이란?

##### Max Pooling
![]()
- 이미지 구역을 쪼개서 그 구역의 최댓값만 취하는 것이다.
- 위의 이미지처럼 맥스풀링을 f=2를 적용하는 것과 같고, s=2 와 같은 효과를 얻는 것이다. 
- 그래서 f와 s는 맥스풀링의 hyperparameter이다.

이렇게 함으로써 얻는게 뭐냐? 가장 큰 수가 특정 특성을 의미할 수 있으므로 그 값을 취함으로써 효율적으로 감지하는 것이다. <br>성능이 좋아서 일반적으로 많이 쓴다. <br>

##### Max Pooling의 특징
- 풀링은 학습할 수 있는 변수가 없다!!! 
    - f와 s가 고정된 값이기 때문에 경사하강이 바꿀게없기때문이다. WOW 
- 입체적인 맥스풀링에서도 위와 같이 적용되는데 **각 채널에 개별적으로 적용된다.** 즉 채널은 그대로 유지된다.
- 맥스풀링에서는 예외를 제외하곤 패딩을 쓰지 않는다.
- 하이퍼파라미터 f=2, s=2가 자주 사용된다.
<br>

##### Average Pooling
맥스풀링과 같지만 최대값 대신 평균값을 취하는 것이다. 맥스풀링이 더 많이 쓰인다.

<br><br>

### CNN Example (LeNet-5와 비슷)
- 레이어1에는 CONV1과 POOL1이 들어있다. 
    - POOL은 하이퍼파라미터가 고정되어있기때문에 그까지 레이어 1로 치기때문.
- 레이어2에는 CONV2와 POOL2가 들어있다.
- 레이어1에서 레이어2까지를 거쳐가면 결과의 높이와 넓이가 작아져있을 것이다. 그 결과를 벡터로 쫙 펴준다. 그 유닛들이 400개라고 치자.
- 400개의 유닛을 가지고 120개의 유닛을 가진 레이어를 만든다. 
    - 400개의 유닛이 120개의 유닛과 완전히 연결되어있기 때문에 fully Connected라고 부른다.
    - 여기서는 FC3이라고 하겠다.
    - 이 것은 마치 단일 신경망층과 유사하다.
- 120개의 유닛을 가지고 84개의 유닛을 가진 레이어를 만든다.
    - 여기서는 FC4라고 하겠다.
- 소프트맥스를 적용해본다.

<br>
 <br>
아무튼 CNN에서 넓이와 높이는 감소하고 채널은 증가하는 것을 볼 수 있다. 

##### CNN 하이퍼파라미터
하이퍼파라미터는 다른 문헌같은 곳에서 참고하는 것이 좋다. 이거는 다음에 더 다루고 CNN이 동작하는 것을 잘 보면 다음과 같은 하이퍼파라미터의 특징이 있다.

- 맥스풀링의 변수는 따로 없다.
- CONV 레이어는 상대적으로 적은 변수를 가진다.
- 대부분의 변수는 FC에 있다.
- 활성값의 크기가 신경망이 깊어질수록 점점 감소한다.


<br><br>

### 왜 CONV인가?
왜 신경망에서 합성곱을 사용하는 것이 유용할까? <br>
이것들을 전부 조합해서 어떻게 train할까?ㄴ

#### 왜에에?
합성곱이 적은 변수를 가질 수 있어서 장점이 있다. 그 적은 변수를 가질 수 있는 이유는 다음과 같다.

- 변수 공유
    - 특성검출기의 값은 입력 이미지의 여러 위치에서 동일하게 사용이 된다. 그래서 합성곱 층의 변수의 수는 작게 유지된다.
- 희소 연결
    - 특정 구간에만 영향을 가지고 나머지 픽셀 값들엔 영향을 주지 않는 것이 희소연결이다.

이를 통해, 신경망의 변수가 줄어서 작은 훈련세트를 가지고도 오버피팅을 방지할 수 있다. <br>
또한 이동 불변성을 포착하는데도 용이하다.
- 이동 불변성(Translation invariance)
    - 사진이 몇 픽셀 이동해도 고양이는 고양이인 것.

<br><br>

#### 마무리..
CNN은 w, b를 파라미터로 비용함수를 적용하고 비용함수를 줄이기 위해 경사하강이나 모멘텀, Adam등등을 사용해서 변수를 최적화 할 수 있다.

<br><br>
강의 노트를 많이 보자.