# ML
# Coursera - CNN - Face Recognition
## What is Face Recognition?
ConvNet 많이 배웠으니까 얼굴 인식을 해보자. <br>
얼굴 인식에서 사용하는 용어들
- Vertification (검증)
    - 이미지, 이름, ID 가 주어짐
    - 그 사람인지 구분
    - 1:1 문제라고 함. 
- Recognition (인식)
    - 데이터 베이스에 K명을 두고 구분
    - 이미지, 이름, ID가 주어짐
    - K명 중에 하나인지 구분
    - Verticifation 보다 어려움
        - `Vertification`의 정확도가 99%라고 할지라도 그것이 K로 많아진다면 에러확률 1%가 K만큼 많아지기 때문

## One Shot Learning
주어진 하나의 사진이나 하나의 training example로 사람을 인식해야한다. 이건 조금 까다롭다<br> 
당연하게도 train 샘플이 없으면 탄탄한 신경망이 이루어질 수 없고 만약에 새로운 사람을 더 인식할때마다 결과값을 바꿔 새로 훈련해야할 것이다. <br>

### `similarity` 함수 학습시키기
그래서 대신 similarity (유사도) 함수를 학습시킨다. <br>
이 함수는 두 개의 이미지를 받아서 차이의 정도를 반환한다. <br>
```
d(img1, img2) = 두 이미지의 차이점 정도
If d(img1, img2) ≤ τ    "same"
If d(img1, img2) ＞ τ    "different"
                 
```
- 비슷할수록 적은 숫자, 차이가 많이 날수록 큰 숫자를 반환
- 차이점의 기준인 하이퍼파라미터 `τ` 를 가지고 예측할 수 있다. 
- Vertification 을 다루는 방법이다.

<br>

Recognition에 적용하려면 
- 두 이미지를 비교하기 위해서 유사도 함수를 적용하고 
- 두번째 이미지도 유사도 함수를 적용하고
- 이런식으로 모든 이미지에 적용해본다.
- 작은 값을 가진 사람을 인식한다.

<br><br>

## Siamese Network (샴 신경망)
유사도 함수를 적용하기 좋은 방법은 Siamese Network를 이용하는 것이다. <br>
이것은 두 개의 입력에 대해 독립적으로 두 개의 ConvNet을 실행한 뒤 비교하는 것이다.

- 두 이미지가 주어지면
- 두 신경망은 같은 변수를 가지고
- CNN에서 FC를 한 마지막 층의 벡터를 인코딩한 함수를 비교한다.
    - 두 사람이 같은 사람인지 알려주는 함수 d를 계산하는 인코딩을 구하고 비교.
    - 즉, 이미지를 입력하면 신경망의 변수들이 인코딩 f(x^(i))를 아웃풋해주는 것.
- 만약 두 인코딩 사이의 거리가 가까우면 같은 사람이고, 멀면 다른 사람이 될 것이다.

```
∥f(x^(i))  - f(x^(j)∥²
```
뭘 하고 있는 것이나면 변수를 학습하려는 것이다. 신경망의 각 층에 대한 변수들이 서로 다르기 때문에 결과적으로 서로 다른 인코딩을 얻는 것이다. 물론 이것을 하려면 역전파를 사용해서 변수들을 다양화해야한다.

<br><br>

## Triplet loss (삼중항 손실 함수)
얼굴 이미지에 대해서 좋은 인코딩을 얻기 위한 방법 중 하나는 Triplet loss 함수에 경사하강법을 정의하고 적용하는 것이다. <br>

### Learning Objective
Triplet loss 를 적용하려면 이미지 쌍들을 비교해야한다. <br>
**Triplet loss 는 항상 하나의 앵커 이미지를 살펴본다음 같은 사람인 것을 뜻하는 positive 이미지와 다른 사람인 것을 뜻하는 Negative 이미지, 앵커 이미지 사이의 `거리` 를 구하는 것이다.** <br>
이렇게 앵커 이미지(A), positive 이미지(P), negative(N) 이미지 총  세개의 이미지를 동시에 보기 때문에 Triplet loss 라는 이름이 붙었다. <br>
이것을 식으로 간략화해보면
- A 인코딩에서 P인코딩을 뺀 값이 작기를 원하고
- 이것은 A 인코딩에서 N인코딩을 뺀 값보다 작거나 같아야한다.

```
∥f(A) - f(P)∥² ≤ ∥f(A) - f(N))∥²

즉, d(A, P)  ≤ d(A, N)이다.
(d는 거리함수)
```
이 표현을 조금 더 파고들어보면 아래와 같아진다.
```
∥f(A)  - f(P)∥² - ∥f(A)  - f(N))∥² ≤ 0
```

<br>

이 식을 만족시킬만한 확실한 방법 중 하나는 모든 것이 0인 것을 학습하는 것이다. f가 항상 0이라면 모두 0이 되고 확실하게 이 식을 만족시킬 수 있게되는 것이다. 하지만 신경망이 모든 인코딩에 대해 0을 출력하지는 않는다. <br>
다른 방법으로는 모든 이미지에 대한 인코딩이 다른 모든 이미지와 같은 경우를 살펴볼 수 있다. 이 경우엔 신경망이 이렇게 하는 것을 방지하기 위해서 단지 0보다 작거나 같을 것을 요구하는 것이 아니라, **0보다 상당히 작은 값을 가지는 것을 요구하는 것이다.** 이렇게 하면 신경망이 확실한 해를 내놓지 못하게 한다. 이 0보다 작은 값을 `-α` 라고하고 하나의 하이퍼파라미터로 정의해둔 식은 다음과 같다. <br>
```
∥f(A)  - f(P)∥² - ∥f(A)  - f(N))∥² ≤ 0 - α
```
```
∥f(A)  - f(P)∥² - ∥f(A)  - f(N))∥² + α ≤ 0 

d(A, P) + α  ≤ d(A, N)
```
- 관습적으로 `-α` 보다는 `+α` 를 사용하고 이것을 `margin(마진)` 이라고 부른다.
- 이 `α` 는 확실한 해를 내놓지 못하게, 즉, 앵커와 (positive, negative)의 사이를 멀어지게 만들어준다.

<br>

### Loss Function
싱글 triplet의 손실함수구하는 법을 알아보자.
- 3개의 이미지가 주어진다.
    - A, P, N
- 손실을 정의한다.
```
L(A, P, N) = ∥f(A)  - f(P)∥² - ∥f(A)  - f(N))∥² + α
```

<br>

- 이 손실이 0보다 작거나 같기를 원하기 때문에 함수와 0사이의 최댓값을 구한다.
    - `∥f(A)  - f(P)∥² - ∥f(A)  - f(N))∥² + α` 가 0보다 작을 때, 0보다 작은 값과 0 사이의 최댓값은 0이기 때문에 손실이 0이 된다.
    - `∥f(A)  - f(P)∥² - ∥f(A)  - f(N))∥² + α` 값이 0 보다 크다면 최댓값의 결과는 ``∥f(A)  - f(P)∥² - ∥f(A)  - f(N))∥² + α` 가 되고 양의 손실을 갖는다.
    - 이것을 통해서 신경망은 음수가 얼마든지 신경을 쓰지 않아도 된다.

```
L(A, P, N) = max(∥f(A)  - f(P)∥² - ∥f(A)  - f(N))∥² + α, 0)
```

<br>
전체적인 비용함수는 모든 트레이닝에대한 손실함수의 합일 것이다 <br>
위에서 봤듯이 꼭 positive가 들어가야한다. 그렇기 때문에 같은 사람에 대한 많은 이미지의 데이터가 필요하다. 천명의 사람에 대해서는 만개의 이미지가 있어야할듯. <br>

<br>

### A, P, N은 어떻게 골라야할까?
만약, A, P, N 을 무작위로 고르면 제약식을 만족하기가 쉬워진다. 확률적으로 (A,N)이 (A,P) 보다 훨씬 다를 것이기 때문이다.
```
d(A, P) + α  ≤ d(A, N)
```
앞에서 봤던 제약식의 d(A, N)이 좌변의 d(A, P)보다 훨씬 클 확률이 높아진다. 이렇게되면 삼중항들이 너무 쉬워져서 신경망이 대부분의 경우에 제약식을 만족할 것이고 그로인해 경사하강법이 아무 역할도 하지 못해 학습이 안되게 된다. <br>
이것을 피하려면 A, P, N을 train하기 힘든 것으로 고르면 된다. d(A, P)와 d(A, N)의 값이 서로 비슷한 A, P, N을 고르면 식이 어려워지기 때문에 이 방법을 쓴다.<br>
이렇게 하면 학습알고리즘이 더 주의를 기울여서 오른쪽 값을 높이고 왼쪽 값을 내려서 왼쪽과 오른쪽 사이에 적어도 마진 `α`가 생기도록 할 수 밖에 없어진다. <br>
일부러 어려우라고 비슷한 값을 떡 하니 내어주면 경사하강법이 이 값들을 서로 멀리 떨어뜨리려고 열일을 하는 것이다. 이렇게 하면 효율이 좋아진다. <br>
<br>

여기서 다시 상기하자면, Triple loss는 face recognition 신경망(샴 네트워크)의 변수를 학습하는 방법 중 하나이다.

<br><br>

## Face Verification and Binary classification
Face Recognition 신경망의 변수를 학습하는 또 다른 방법 중 하나를 알아보자. <br>

- 두 개의 샴 신경망을 가지고 임베딩을 계산한다.
- 이것들을 로지스틱 회귀 유닛에 입력하여 예측한다.
    - 결과값은 1, 0이 된다.

이렇게 Face Recognition 문제를 이진 분류로 다뤄버리는 것이다. Triple Loss의 대안이라고도 할 수 있다. <br>
여기서 로지스틱 회귀 유닛이 뭘 하고 있는지 식을 뜯어보며 자세히 살펴보자. <br>


![Face Verification and Binary classification]()

- 인코딩들을 단지 대입하지 않고 인코딩들 사이의 차를 구한다.
    - f(x^(i)) 는 이미지 x^(i)의 인코딩이다. 
    - k는 벡터의 k번째 구성요소를 가져왔다는 뜻이다.
- 각각의 쌍에 대한 두 인코딩의 차에 대해서 절댓값을 취한다.
- 그렇게 나온 값들의 숫자들을 피쳐로 생각하고 로지스틱 회귀에 집어넣는다.
- 적절한 가중치를 훈련한다.

<br>
이렇게 해주면 샴 신경망을 훈련할 때 한 쪽 신경망과 다른 신경망이 똑같거나 거의 같은 변수들을 가지게 되므로 학습이 꽤 잘 된다. 
<br>

또한 임베딩을 매번 계산하는 대신 미리 계산할 수 있으므로 **인식하려고 하는 쪽의 신경망은 미리 계산된 다른 인코딩과 비교할 수 있게되고** 그것을 사용해서 y예측값을 구할 수으므로 매번 인코딩을 계산할 필요가 없기 때문에 계산량을 상당히 줄일 수 있다. <br>
결론적으로 세쌍 대신 쌍으로 된 훈련세트를 만들고 같은 사람의 사진일 때 target label을 1로, 다를 땐 0으로 만든다. 그리고 서로 다른 쌍들을 사용하여 역전파를 하고 학습한다.

<br><br><br>

# Coursera - CNN - Neural Style Transfer

##  Neural Style Transfer (신경망 스타일 변형) 이 뭔데?
가장 흥미로운 응용이라고 할 수 있다. 나중에 프로그래밍 과제로 줄 것임 ^-^ <br>
사진으로 한 방에 이해할 수 있음. 참고로 논문이 쉽다고 하니 읽어봐도 좋을 듯.

![Neural Style Transfer]()

<br>
스타일 변형의 핵심은 신경망의 얕은 층과 deep한 층에서 추출된 피쳐(특성)을 잘 봐야한다. 이 핵심을 잘 알기 위해선 신경망의 층들이 실제로 무엇을 계산하는지를 알아야한다. 그 직관을 얻어보자.

## What are deep CNs learning?
CNN이 뭘 학습하는 것일까? <br>
- 첫번째 레이어의 `유닛` 을 하나골라보자.
- `유닛` 의 activation을 최대화 할 수 있는 9개의 `이미지 patche`들을 찾아보자.
    - 어떤 이미지가 그 유닛의 활성값을 최대화하는지 찾는 것
    - 첫번째 층의 유닛은 신경망의 비교적 작은 부분만 보는 것을 명심
    - 이것으로 유닛이 무엇을 찾는지를 알 수 있다
        - e.g) 9개의 이미지 패치들이 색이 초록색인 오른쪽 대각선만 모으고 있다던지
- 첫번째 레이어의 `다른 유닛`들을 골라서 같은 과정을 반복한다.

이렇게 하면 **첫번째 층의 훈련된 은닉 유닛들은 종종 모소리 또는 색깔과 같은 비교적 단순한 특징을 찾는 것을 볼 수 있다.**

<br>

더 깊은 층의 은닉 유닛에 위의 방식을 적용해보면 어떨까? 깊은 층은 무엇을 학습하는 것일까? 저 방식을 적용해보았더니, **깊은 층에서는 은닉 유닛들이 이미지의 더 큰 부분을 보고있었다.** 깊은 층에서는 대각선을 보는 것이 아니라 강아지의 얼굴을 보고있는 것이다. 즉, 깊은 층으로 갈수록 더 복잡한 특성 또는 패턴을 검출해내는 것이다. <br>
이러한 직관을 알았다면 이제 Neural Style Transfer 알고리즘을 만들어 보자.

<br><br>

## Neural Style Transfer Cost Function
알고리즘을 만들기 전에 비용 함수를 정의해보자.
Content(C) 와 Style(S) 그리고 결과물 Generated image(G) 이 있다. <br>
우리는 특정 생성 이미지가 얼마나 좋은지 측정하기 위하여 G에 대한 비용함수 J(G)를 정의하고 경사하강법을 이용하여 J(G)를 최소할 것이다. 그럼 얼마나 좋은지를 어떻게 알까? <br>
그러기 위해선 비용 함수의 두 가지 부분을 정의해야한다. <br>
<br>

- `Content Cost`
```
J(G) = J_content(C, G)
```
Content Cost로 **생성한 이미지와 Content 이미지의 내용이 얼마나 비슷한가** 를 알아볼 수 있다.

<br>

- `Style Cost`
```
J(G) = J_content(C, G) + J_style(S, G)
```
Style Cost는 **생성한 이미지와 style이미지의 style이 얼마나 비슷한가** 를 알아보는 것이다.  

<br>

```
J(G) = α*J_content(C, G) + β*J_style(S, G)
```
두 가지 부분을 정의하였으니 마지막으로 하이퍼라미터를 이용하여 `content cost`와 `style cost` 사이의 가중치를 둔다.

<br>

### 생성된 이미지 G를 찾기
- 생성 이미지 G를 무작위로 초기화한다.
    - e.g) 100 * 100 * 3
    - 픽셀값들이 랜덤하게 생성됨
- J(G) 를 이용하여 비용함수를 정의
- 경사하강법을 사용해서 J(G)를 최소화한다.
    - G = G - d/dg * J(G)
    - 이 과정에서 실제로 이미지 G의 픽셀값들을 업데이트한다.


<br>

J(G)는 이제 알겠는데 `content cost`와 `style cost`는 어떻게 정의해야할까? 계속 알아보자.

<br><br>

## Content Cost Function

```
J(G) = α*J_content(C, G) + β*J_style(S, G)
```

- Content cost를 계산하기 위해 히든레이어 `l` 을 사용한다고 해보자.
    - `l` 이 아주 작은 숫자(앞쪽 층)라면 generated image의 픽셀값과 content 이미지의 픽셀값을 유사하게 만들것이다.
    - `l` 이 큰 숫자(아주 깊은 층)을 사용한다면 content image에 개가 있을 때 generated image 의 어딘가에 개가 있도록 할 것이다.
    - 실제로는 이 l이 신경망의 아주 얕은 층과 너무 깊은 층의 사이에 있도록 해야한다.
- pre-trained ConvNet을 이용할 것이다.
    - e.g) VGG 신경망같은 것
- a^[l]^(C)와 a^[l]^(G) 를 두 이미지 C와 G에 대한 l레이어의 활성값으로 둔다.
    - 주어진 content image와 generated image가 content 면에서 얼마나 비슷한지를 측정하는 것이다.
- 만약 저 **두 활성값이 비슷하다면 두 이미지는 content가 비슷하다고 볼 수 있다.**

```
J(C, G) = (정규화상수) * ∥a^[l]^(C)  - a^[l]^(G)∥² 
```
- l 레이어의 각 이미지 C와 G에 대한 활성값 차의 제곱의 element-wise 합이다.


<br><br>
